{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to import Kaggle dataset in Google Colab",
      "provenance": [],
      "authorship_tag": "ABX9TyMWZ3xHKS41b5Sj74ZK/lsy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronee12/Computer-Vision-Deep-learning-Work-Shop/blob/master/How_to_import_Kaggle_dataset_in_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbQBf0J94knb",
        "colab_type": "text"
      },
      "source": [
        "**How to upload Kaggle datasets into Google Colab**\n",
        "\n",
        "Before going through below steps, first go to kaggle account and create a API token.\n",
        "\n",
        "How to create a API token\n",
        "\n",
        "1. Go to **Kaggle.com** and Sign in if you are logged out.\n",
        "2. Click on profile picture from top-right corner.\n",
        "3. Select **My Account** from dropdown menu.\n",
        "4. Scroll and find **API** section. Click **Create New API Token**. Note that if you created any API earlier, you need to first click on **Expire API token** to expire previous API token then you can create a new API token.\n",
        "5. A **kaggle.json** named file will be downloaded. Save it some known place on your computer.\n",
        "\n",
        "Now back to this notebook and follow the below steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwv91XPu2DVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTnd-Ji72cwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3l3PZAF8sh4",
        "colab_type": "text"
      },
      "source": [
        "Here, you need to upload the **kaggle.json** file you downloaded earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNHNxQLG2jnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpYa_nsC2lLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create new directory and named \"kaggle\"\n",
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPxu5RiG3Dkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copy the json file into the kaggle directory\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgeKlvkU3Izb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU3dxVRP3YjT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "35a1e5c1-6ec8-46d6-c0db-5b9d47f0c37d"
      },
      "source": [
        "#check to see kaggle imported in colab successfully or not.\n",
        "!kaggle datasets list"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                         title                                                size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "allen-institute-for-ai/CORD-19-research-challenge           COVID-19 Open Research Dataset Challenge (CORD-19)    2GB  2020-05-02 20:35:01          63384  \n",
            "divyansh22/us-border-crossing-data                          US Border Crossing Data                               2MB  2020-04-19 09:38:10           1452  \n",
            "roche-data-science-coalition/uncover                        UNCOVER COVID-19 Challenge                          142MB  2020-04-29 22:47:23           7561  \n",
            "baltacifatih/turkish-lira-banknote-dataset                  Turkish Lira Banknote Dataset                         3GB  2020-04-19 14:48:39            131  \n",
            "doaaalsenani/usa-cers-dataset                               US Cars Dataset                                      66KB  2020-04-22 14:38:05           2580  \n",
            "justinas/housing-in-london                                  Housing in London                                   169KB  2020-04-29 18:43:38           1520  \n",
            "steveahn/memory-test-on-drugged-islanders-data              Memory Test on Drugged Islanders Data                 3KB  2019-08-20 18:54:37            817  \n",
            "ankurzing/sentiment-analysis-for-financial-news             Sentiment Analysis for Financial News               904KB  2020-04-26 18:41:22            491  \n",
            "phiitm/reddit-india-flair-detector                          Reddit India Flair Detector                          48MB  2020-04-27 20:27:24             89  \n",
            "slayomer/forbes-celebrity-100-since-2005                    Forbes Celebrity 100 since 2005 (for Racing Bar)     12KB  2020-04-26 15:51:16            324  \n",
            "mariaren/covid19-healthy-diet-dataset                       COVID-19 Healthy Diet Dataset                        82KB  2020-05-08 16:40:18           1221  \n",
            "jessemostipak/animal-crossing                               Animal Crossing                                     754KB  2020-05-04 15:30:32            132  \n",
            "marcelopesse/cartier-jewelry-catalog                        Cartier Jewelry - Catalog                            22KB  2020-04-27 05:03:23            177  \n",
            "benroshan/factors-affecting-campus-placement                Campus Recruitment                                    5KB  2020-04-11 11:09:02           3256  \n",
            "bobbyscience/league-of-legends-diamond-ranked-games-10-min  League of Legends Diamond Ranked Games (10 min)     539KB  2020-04-13 13:53:02           1556  \n",
            "fireballbyedimyrnmom/us-counties-covid-19-dataset           US counties COVID 19 dataset                          1MB  2020-05-08 12:26:09           6181  \n",
            "divyansh22/flight-delay-prediction                          January Flight Delay Prediction                      23MB  2020-04-14 13:15:41           1293  \n",
            "clmentbisaillon/fake-and-real-news-dataset                  Fake and real news dataset                           41MB  2020-03-26 18:51:15           3333  \n",
            "ikiulian/global-hospital-beds-capacity-for-covid19          Global Hospital Beds Capacity (for covid-19)        284KB  2020-04-26 09:39:35           1535  \n",
            "praveengovi/coronahack-chest-xraydataset                    CoronaHack -Chest X-Ray-Dataset                       1GB  2020-03-20 01:26:40           2145  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2hR6joP_izE",
        "colab_type": "text"
      },
      "source": [
        "You can even **filter** the dataset list. For example, If I want to see all the dataset that include word `classification`\n",
        "Then I should run the bellow command "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w-TO5MI_VxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "cddeb635-0a7f-4844-c42f-ad0606e613b0"
      },
      "source": [
        "!kaggle datasets list -s classification\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                   title                                   size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------  -------------------------------------  -----  -------------------  -------------  \n",
            "uciml/mushroom-classification                         Mushroom Classification                 34KB  2016-12-01 23:08:00          43323  \n",
            "uciml/glass                                           Glass Classification                     3KB  2017-01-27 17:27:48          11568  \n",
            "asdasdasasdas/garbage-classification                  Garbage Classification                  82MB  2018-11-24 05:09:23           4253  \n",
            "puneet6060/intel-image-classification                 Intel Image Classification             346MB  2019-01-30 09:22:58          13394  \n",
            "uciml/zoo-animal-classification                       Zoo Animal Classification                2KB  2016-12-24 18:05:10          13955  \n",
            "iabhishekofficial/mobile-price-classification         Mobile Price Classification             71KB  2018-01-28 08:44:24          21863  \n",
            "techsash/waste-classification-data                    Waste Classification data              427MB  2019-06-16 03:24:52           4083  \n",
            "loveall/cervical-cancer-risk-classification           Cervical Cancer Risk Classification      9KB  2017-08-31 01:02:22          12603  \n",
            "crowdflower/twitter-user-gender-classification        Twitter User Gender Classification       3MB  2016-11-21 01:48:06          12012  \n",
            "lodetomasi1995/income-classification                  Income classification                  459KB  2019-03-26 13:14:12           3124  \n",
            "hb20007/gender-classification                         Gender Classification                   666B  2018-02-21 18:07:51           1592  \n",
            "olgabelitskaya/classification-of-handwritten-letters  Classification of Handwritten Letters  181MB  2018-08-25 23:19:15           3612  \n",
            "mmoreaux/environmental-sound-classification-50        Environmental Sound Classification 50    1GB  2018-10-26 15:54:57           2111  \n",
            "shrutimehta/nasa-asteroids-classification             NASA: Asteroids Classification           3MB  2018-03-01 01:16:23           1075  \n",
            "team-ai/spam-text-message-classification              Spam Text Message Classification       208KB  2017-08-20 06:32:31           2805  \n",
            "ali2020armor/taekwondo-techniques-classification      Taekwondo Techniques Classification    152KB  2017-01-18 18:17:31            540  \n",
            "roshansharma/online-shoppers-intention                Online Shopper's Intention             252KB  2019-05-23 05:28:16           6316  \n",
            "uciml/german-credit                                   German Credit Risk                      11KB  2016-12-14 21:25:02          15288  \n",
            "playlist/men-women-classification                     Men/Women Classification                 1GB  2019-04-09 14:14:58           1807  \n",
            "ananthu017/question-classification                    Question Classification                137KB  2018-10-06 14:14:14            543  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjsZ7lWc_ACM",
        "colab_type": "text"
      },
      "source": [
        "Now you are ready to upload dataset from Kaggle into this notebook.\n",
        "\n",
        "Go to data section of your desired dataset. There you should a API command. Copy the command and paste directly in notebook. and run.\n",
        "\n",
        "Dataset will be uploaded into colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nGjUepM3cw-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "6d2ddd81-e5f0-47cd-f195-f0c75548c5e7"
      },
      "source": [
        "!kaggle competitions download -c 'aerial-cactus-identification'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.zip to /content\n",
            " 26% 5.00M/19.2M [00:00<00:01, 11.9MB/s]\n",
            "100% 19.2M/19.2M [00:00<00:00, 35.6MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/667k [00:00<?, ?B/s]\n",
            "100% 667k/667k [00:00<00:00, 44.5MB/s]\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/160k [00:00<?, ?B/s]\n",
            "100% 160k/160k [00:00<00:00, 50.0MB/s]\n",
            "Downloading test.zip to /content\n",
            "100% 4.20M/4.20M [00:00<00:00, 20.5MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}